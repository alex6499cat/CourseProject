{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "These imports are slightly less than in `con_sent.ipynb` since this notebook is mean to play around with the results of the sentiment analysis rather than actually run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bisect\n",
    "from gensim import models,corpora,utils\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Below imports `full_df` which is a pandas dataframe, this will take around 4-5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:47+00:00</td>\n",
       "      <td>I understand. I would like to assist you. We ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:11:45+00:00</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:08:27+00:00</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 21:54:49+00:00</td>\n",
       "      <td>Please send us a Private Message so that we c...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:49:35+00:00</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0   author_id  inbound                created_at  \\\n",
       "tweet_id                                                              \n",
       "1                  0  sprintcare    False 2017-10-31 22:10:47+00:00   \n",
       "2                  1      115712     True 2017-10-31 22:11:45+00:00   \n",
       "3                  2      115712     True 2017-10-31 22:08:27+00:00   \n",
       "4                  3  sprintcare    False 2017-10-31 21:54:49+00:00   \n",
       "5                  4      115712     True 2017-10-31 21:49:35+00:00   \n",
       "\n",
       "                                                       text response_tweet_id  \\\n",
       "tweet_id                                                                        \n",
       "1          I understand. I would like to assist you. We ...                 2   \n",
       "2             @sprintcare and how do you propose we do that                     \n",
       "3         @sprintcare I have sent several private messag...                 1   \n",
       "4          Please send us a Private Message so that we c...                 3   \n",
       "5                                        @sprintcare I did.                 4   \n",
       "\n",
       "         in_response_to_tweet_id  \n",
       "tweet_id                          \n",
       "1                            3.0  \n",
       "2                            1.0  \n",
       "3                            4.0  \n",
       "4                            5.0  \n",
       "5                            6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv(\"emojiTranslatedCleanedNoUnderscore.csv\", na_filter= False, parse_dates = ['created_at'],\n",
    "                      dtype = {'tweet_id': str,'in_response_to_tweet_id': str, 'inbound':bool, 'response_tweet_id':str })\n",
    "full_df.set_index(\"tweet_id\", inplace = True)\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below imports `sentiment_pairs_df` which is a pandas dataframe which holds the three tweets that make up the (sub)thread in which the difference in sentiment is recorded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_tweet_id</th>\n",
       "      <th>second_tweet_id</th>\n",
       "      <th>third_tweet_id</th>\n",
       "      <th>company</th>\n",
       "      <th>sentiment_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            first_tweet_id  second_tweet_id  third_tweet_id     company  \\\n",
       "Unnamed: 0                                                                \n",
       "0                        8                6               5  sprintcare   \n",
       "1                        5                4               3  sprintcare   \n",
       "2                        3                1               2  sprintcare   \n",
       "3                       18               17              16  sprintcare   \n",
       "4                       16               15              12  sprintcare   \n",
       "\n",
       "            sentiment_change  \n",
       "Unnamed: 0                    \n",
       "0                   1.000000  \n",
       "1                  -1.000000  \n",
       "2                   1.000000  \n",
       "3                   1.333333  \n",
       "4                  -0.500000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pairs_df = pd.read_csv(\"con_sent.csv\")\n",
    "sentiment_pairs_df.set_index('Unnamed: 0', inplace = True)\n",
    "\n",
    "num_rows = sentiment_pairs_df.shape[0]\n",
    "sentiment_pairs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "Below are a wealth of documented functions used both to analyze what you saw in our presentation as well as a few extras to play around with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Pair/Subthread Filtering\n",
    "\n",
    "Functions in this section are meant to be used to grab a subset of the tweet response pairs. **They tend to take several minutes** so it's recommended that you always save the result when using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the sentiment change threshold that will return at least the top `percent` of all\n",
    "# tweet response pairs. This may return more than just the specified percent since many pairs\n",
    "# below the percent cutoff may have the same sentiment change\n",
    "def lower_sent_for_top_p_responses(percent=.001):\n",
    "    num_top = round(num_rows * percent)\n",
    "    deltas = []\n",
    "    \n",
    "    for row in range(num_rows):  \n",
    "        change = sentiment_pairs_df.iloc[row][4]\n",
    "        bisect.insort(deltas, change)\n",
    "        \n",
    "        if len(deltas) > num_top:\n",
    "            deltas.pop(0)\n",
    "            \n",
    "    return deltas[0]    \n",
    "\n",
    "# Returns the sentiment change threshold that will return at least the bottom `percent` of all\n",
    "# tweet response pairs. This may return more than just the specified percent since many pairs\n",
    "# below the percent cutoff may have the same sentiment change\n",
    "def upper_sent_for_bottom_p_responses(percent=.001):\n",
    "    num_top = round(num_rows * percent)\n",
    "    deltas = []\n",
    "    \n",
    "    for row in range(num_rows):  \n",
    "        change = sentiment_pairs_df.iloc[row][4]\n",
    "        bisect.insort(deltas, change)\n",
    "        \n",
    "        if len(deltas) > num_top:\n",
    "            deltas.pop(num_top)\n",
    "            \n",
    "    return deltas[-1]    \n",
    "\n",
    "# Returns the row ids of `sentiment_pairs_df` that are above (optionally inclusive) a desired\n",
    "# sentiment change\n",
    "def get_rows_above_delta(delta=2, inclusive=False):\n",
    "    row_ids = []\n",
    "    \n",
    "    for row in range(num_rows):\n",
    "        row_data = sentiment_pairs_df.iloc[row]\n",
    "        change = row_data[4]\n",
    "        if (change >= delta if inclusive else change > delta):\n",
    "            row_ids.append(row_data)\n",
    "        \n",
    "    return row_ids\n",
    "\n",
    "# Returns the row ids of `sentiment_pairs_df` that are below (optionally inclusive) a desired\n",
    "# sentiment change\n",
    "def get_rows_below_delta(delta=2, inclusive=False):\n",
    "    row_ids = []\n",
    "    \n",
    "    for row in range(num_rows):\n",
    "        row_data = sentiment_pairs_df.iloc[row]\n",
    "        change = row_data[4]\n",
    "        if (change <= delta if inclusive else change < delta):\n",
    "            row_ids.append(row_data)\n",
    "        \n",
    "    return row_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Functions in this section to create frequencies/unigrams/multinomial distributions of a collection of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('stopwords.txt',\"r\")\n",
    "stoplist = stopwords.read().splitlines() \n",
    "\n",
    "# Not meant to be called on its own (just a helper function)\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "# Not meant to be called on its own (just a helper function)\n",
    "def get_texts(rows):\n",
    "    texts = []\n",
    "    for row in rows:\n",
    "        cs_tweet_id = row[1]\n",
    "        cs_tweet_text = full_df.loc[str(cs_tweet_id)]['text']\n",
    "        cs_tweet_text = [word for word in cs_tweet_text.lower().split() if word not in stoplist]\n",
    "        texts.append(cs_tweet_text)\n",
    "        \n",
    "    return texts\n",
    "\n",
    "# Not meant to be called on its own (just a helper function)\n",
    "def build_frequency_map(rows):\n",
    "    tweet_list = list(sent_to_words(get_texts(rows)))\n",
    "    \n",
    "    freq = defaultdict(int)\n",
    "    total = 0\n",
    "    \n",
    "    for text in tweet_list:\n",
    "        for token in text:\n",
    "            freq[token] += 1\n",
    "            total += 1\n",
    "            \n",
    "    return freq, total\n",
    "\n",
    "# Takes rows corresponding to `sentiment_pairs_df` and builds a map of the top `top` words by\n",
    "# frequency, excluding common stop words\n",
    "def top_words(rows, top):\n",
    "    frequency, total = build_frequency_map(rows)\n",
    "    measures = []\n",
    "    \n",
    "    for word in frequency:\n",
    "        count = frequency[word]\n",
    "        if len(measures) < top or count > measures[0]:\n",
    "            bisect.insort(measures, count)\n",
    "            if len(measures) > top:\n",
    "                measures.pop(0)\n",
    "    ret = []\n",
    "    for word in frequency:\n",
    "        count = frequency[word]\n",
    "        if count >= measures[0]:\n",
    "            ret.append([word, count*100.0/total])\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility\n",
    "\n",
    "These functions are meant to help visualize output or transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will somewhat-pretty print the tweet response pairs of `rows`. When num_to_print is specified,\n",
    "# only the first `num_to_print` rows will be printed, otherwise all will be printed.\n",
    "separator = '----------------------------------------'\n",
    "def print_tweets(rows, num_to_print=None):\n",
    "    print(separator)\n",
    "    for i in (range(len(rows)) if num_to_print == None else num_to_print):\n",
    "        row = rows[i]\n",
    "        first_text = full_df.loc[str(row[0])]['text']\n",
    "        second_text = full_df.loc[str(row[1])]['text']\n",
    "        third_text = full_df.loc[str(row[2])]['text']\n",
    "        \n",
    "        print(\"customer:\", first_text)\n",
    "        print(\"response:\", second_text)\n",
    "        print(\"customer:\", third_text)\n",
    "        print(separator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground!\n",
    "\n",
    "A few usage examples are given if you are unsure where to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "customer: somebody from @VerizonSupport please help meeeeee  weary face  weary face  weary face  weary face  I'm having the worst luck with your customer service\n",
      "response:  Help has arrived! We are sorry to see that you are having trouble. How can we help?\n",
      "customer: @VerizonSupport I finally got someone that helped me, thanks!\n",
      "----------------------------------------\n",
      "customer: @AppleSupport Thanks, thing is I still have like 81 cents in credit and won't let me do that until I have zero credit\n",
      "response:  Try contacting our iTunes Store team here for more help: \n",
      "customer: @AppleSupport Awesome, thanks\n",
      "----------------------------------------\n",
      "customer: @Uber_Support Thanks - our baby is &lt;12mos and we need our car seat to fly so I was wondering if we can bring our own car seat and install via belt buckle in any UberX to go to the airport\n",
      "response:  Hi there! Yes, you're always welcome to bring your own car seat along for the ride.\n",
      "customer: @Uber_Support Ok great, thanks!\n",
      "----------------------------------------\n",
      "customer: @ATVIAssist Black ops 3 on Xbox one for me runs bad every game and every map I have stutter lag problems and it’s annoying \n",
      "response:  Good evening, I'm not seeing much connection issues occurring. Are you playing on a wired or wireless connection? \n",
      "customer: @ATVIAssist Wired and I’ve got fiber Internet so it’s nothing to do with connection plus I’m playing solo on zombies so should run totally fine\n",
      "----------------------------------------\n",
      "customer: Another awful experience with ; never forget  ;retweet and fly ANY other carrier;\n",
      "response:  This definitely isn't what we want to hear, Lynn. Can you tell us what happened? \n",
      "customer: @British_Airways  Stop wining and fly with Albatros Airlines, good luck.\n",
      "----------------------------------------\n",
      "customer: So my little girl hasnt finished a pot of porridge yet, tried her on @AldiUK this morning and all gone  relieved face  face savoring food \n",
      "response:  Great to hear that, Ellie!  bowl with spoon \n",
      "customer: @AldiUK She loved it!\n",
      "----------------------------------------\n",
      "customer: @VirginTrains just to check - if I have an off peak ticket can I travel on any train?\n",
      "response:  On any Off Peak train yes. \n",
      "customer: @VirginTrains Amazing thanks\n",
      "----------------------------------------\n",
      "customer: @VirginTrains your service more often than not Is on time and for that I am grateful however is it entirely necessary for your trains to smell so bad?\n",
      "response:  Thanks Gemma, sad to hear you think our trains smell :( Which service are you on and we will pass this back to our maintenance team? \n",
      "customer: @VirginTrains Euston to Piccadilly, thank you  smiling face with smiling eyes \n",
      "----------------------------------------\n",
      "customer: Fingers crossed my blog business cards from @MOO arrive before 5pm today or I'm screwed lol\n",
      "response:  Hi Abbigayle, we've checked this for you and it's currently with the courier, so all is still on track for a delivery today! Fingers crossed :)\n",
      "customer: @MOO Awesome thank you smiling face ️\n",
      "----------------------------------------\n",
      "customer: @Delta we thought the hour flight delay was bad enough until we got to baggage claim and we are over an hour waiting for bags...3894\n",
      "response:  Hi Debra, I'm very sorry your bags took so long to arrive at the belt. That is unacceptable. 1/2 *TJW\n",
      "customer: @Delta Customer service was very pleasant ... they tried finding someone to get them an answer ....definitely unusual\n",
      "----------------------------------------\n",
      "customer: really getting inpatient with  and their iPhones  grinning face with sweat  face with rolling eyes  person shrugging  light skin tone ‍ female sign ️\n",
      "response:  Exactly which phone did you order? \n",
      "customer: @USCellularCares iPhone 8+ 64GB gold\n",
      "----------------------------------------\n",
      "customer:  worst cab service by Uber never recommend to any to use it\n",
      "response:  So sorry about the trouble! Please send us a DM with your email address and more details so we can connect.\n",
      "customer: @Uber_Support 10 mints over cancel the ride , for that also you charged us\n",
      "----------------------------------------\n",
      "customer: Thanks to   and @Ask_Spectrum for always having my Back(up) and making sure I don't lose images on Football nights!!\n",
      "response:  Let us know if there's anything we may be able to help you with, we'll be glad to assist via DM. -CP\n",
      "customer: @Ask_Spectrum It was a compliment that everything was working great...\n",
      "----------------------------------------\n",
      "customer:  can I open a joint bank account with someone I am not married to?\n",
      "response:  For US accts yes. I sent you a DM providing the info needed to open an acct. If this is for another country pls LMK. TY*TW \n",
      "customer: @AskCiti  thumbs up \n",
      "----------------------------------------\n",
      "customer:  very unhappy services provided promised something  doing something very unhappy with this @AmazonHelp\n",
      "response:  Sorry to know that. Could you please let us know more about what went wrong? We'll definitely look into it. \n",
      "customer: @AmazonHelp Ur customer care representative promised me for paying back my Amazon pay balance into my account after the refund into Amazon wallet\n",
      "----------------------------------------\n",
      "customer: Holy crap I'm flying @AlaskaAir more often, this legroom is insane \n",
      "response:  Now sit back and enjoy the ride! -Kimball\n",
      "customer: @AlaskaAir It was a great flight, wonderful crew, good plane, good service\n",
      "----------------------------------------\n",
      "customer: @AmericanAir When are flights out of PHL going to receive the same entertainment options as flights from DFW westbound?\n",
      "response:  We're working on updating our flights and are adding new planes every week. We can't wait for you to fly on one!\n",
      "customer: @AmericanAir Excellent - thank you for the info!\n",
      "----------------------------------------\n",
      "customer:  horrible customer service, rude, and unable to provide assist\n",
      "response:  Hi, sorry for any lapse in service. What is the general nature of your concern? ^Clarissa\n",
      "customer: @AskAmex I applied for a CC stating I’d receive a $150 credit on my first statement, your customer service now says I’m ineligible\n",
      "----------------------------------------\n",
      "customer:  horrible customer service, rude, and unable to provide assist\n",
      "response:  Hi, sorry for any lapse in service. What is the general nature of your concern? ^Clarissa\n",
      "customer: @AskAmex I applied for a CC stating I’d receive a $150 credit on my first statement, your customer service now says I’m ineligible\n",
      "----------------------------------------\n",
      "customer:  horrible customer service, rude, and unable to provide assist\n",
      "response:  Hi, sorry for any lapse in service. What is the general nature of your concern? ^Clarissa\n",
      "customer: @AskAmex I applied for a CC stating I’d receive a $150 credit on my first statement, your customer service now says I’m ineligible\n",
      "----------------------------------------\n",
      "customer:  horrible customer service, rude, and unable to provide assist\n",
      "response:  Hi, sorry for any lapse in service. What is the general nature of your concern? ^Clarissa\n",
      "customer: @AskAmex I applied for a CC stating I’d receive a $150 credit on my first statement, your customer service now says I’m ineligible\n",
      "----------------------------------------\n",
      "customer:  horrible customer service, rude, and unable to provide assist\n",
      "response:  Hi, sorry for any lapse in service. What is the general nature of your concern? ^Clarissa\n",
      "customer: @AskAmex I applied for a CC stating I’d receive a $150 credit on my first statement, your customer service now says I’m ineligible\n",
      "----------------------------------------\n",
      "customer:  horrible customer service, rude, and unable to provide assist\n",
      "response:  Hi, sorry for any lapse in service. What is the general nature of your concern? ^Clarissa\n",
      "customer: @AskAmex I applied for a CC stating I’d receive a $150 credit on my first statement, your customer service now says I’m ineligible\n",
      "----------------------------------------\n",
      "customer: @AmazonHelp @AmazonHelp bloody hell , got no response u know what just give me my refund that's it , want nothing else give the refund , blocked my money u cheaters, forget replacement just give refund\n",
      "response:  Apologies, please respond to the email sent from our Account Specialist team. I am sure you issue will be addressed soon. Thank you for understanding. \n",
      "customer: @AmazonHelp I am fed up of going to the link dropping up the details and now going through the email , u just give me my refund, u guyz have simply blocked my money just give refund i dont want replacement and stuff, just refund thats it and I dont have time to reply to u guyz just refund it\n",
      "----------------------------------------\n",
      "customer: @DellCares Hi, I notice you don't sell 32gb of ram on your aus website, I just bought a inspiron 5770, what is the recommended ram details for a 32gb upgrade?\n",
      "response:  Hi Simon,The system has Two SODIMM slots and supports Dual-channel DDR4 modules upto 2400 MHz upto 16GB on each slot. If you have any further queries, please DM the service tag. To locate the service tag of the computer refer to \n",
      "customer: @DellCares Great thanks  thumbs up \n",
      "----------------------------------------\n",
      "customer: @Uber_Support do you know when the next flat fare package goes on sale for Los Angeles? I usually get an email, but I haven't seen one yet.\n",
      "response:  Thank you for reaching out to us. No word at the moment. You should receive an email if you're able to purchase them once they're available.\n",
      "customer: @Uber_Support Thanks  thumbs up \n",
      "----------------------------------------\n",
      "customer: @AmazonHelp i cannot log i to my account as my account has been locked\n",
      "response:  This link will allow you to contact us and bypass log in for now. Please click here: say?  \n",
      "customer: @AmazonHelp Thanks I got my refund  slightly smiling face  thumbs up \n",
      "----------------------------------------\n",
      "customer: My dumb #iPhone constantly pauses music and podcasts (and plays them when app not even open) whenever I use headphones @AppleSupport help me  weary face  weary face  weary face \n",
      "response:  It’s important for your music and podcasts to work correctly on your iPhone! Let’s go through some troubleshooting so we can get to the bottom of this. To start, which version of iOS are you running?\n",
      "customer: @AppleSupport It’s iOS 11.1.2  an iPhone 7+\n",
      "----------------------------------------\n",
      "customer: My dumb #iPhone constantly pauses music and podcasts (and plays them when app not even open) whenever I use headphones @AppleSupport help me  weary face  weary face  weary face \n",
      "response:  It’s important for your music and podcasts to work correctly on your iPhone! Let’s go through some troubleshooting so we can get to the bottom of this. To start, which version of iOS are you running?\n",
      "customer: @AppleSupport It’s iOS 11.1.2  an iPhone 7+\n",
      "----------------------------------------\n",
      "customer: @AmazonHelp Not yet but will not be surprised due to the fact that it has not yet been dispatched\n",
      "response:  No worries, Rory. It's not uncommon for items to ship closer to the delivery date. In some cases, items may even be shipped on the day they're due to be delivered. We never want to miss our mark, so please keep us posted! \n",
      "customer: @AmazonHelp  thumbs up \n",
      "----------------------------------------\n",
      "customer:  don't answer emails for MFA support, soooo... frustrating!\n",
      "response:  Hi, Scott. Our MFA team has sent you an email. Please have a look at it for further assistance. \n",
      "customer: @AWSSupport Awesome, this is great!\n",
      "----------------------------------------\n",
      "customer: @ArgosHelpers I reserved it last night to collect today but not gonna be back in time but don't know how to extend to tomorrow morning\n",
      "response:  pop a DM with the reverse number, and I will look into extending it for you :) - Carl\n",
      "customer: @ArgosHelpers Great thanks I will now!\n",
      "----------------------------------------\n",
      "customer: my chicken bake was stone cold  raised hand  medium light skin tone  @GreggsOfficial sort it out\n",
      "response:  We don't advertise our food as hot Becca. You can find out more here  backhand index pointing right  \n",
      "customer: @GreggsOfficial some advice though they taste a lot better when they’re warm maybe you should keep them warm instead\n",
      "----------------------------------------\n",
      "customer: @Postmates_Help I wish I could 'favorite' some restaurants to create a short list of places I order from or want to order from\n",
      "response:  Good idea! We'll pass that along :)\n",
      "customer: @Postmates_Help  thumbs up  medium skin tone  thumbs up  medium skin tone \n",
      "----------------------------------------\n",
      "customer: @Safaricom_Care Just paid for my subscription but it's not activating\n",
      "response:  Hey Carol, it is now active. \n",
      "customer: @Safaricom_Care Awesome service thank you\n",
      "----------------------------------------\n",
      "customer: @AppleSupport hi is this something i need to worry about or is it a fake? \n",
      "response:  That message doesn't appear to be from us. You can use the steps here to check further and report it: \n",
      "customer: @AppleSupport great thanks!\n",
      "----------------------------------------\n",
      "customer: Hey @GWRHelp, can I use my reading to Paddington season ticket on a reading to waterlooo train tomorrow?\n",
      "response:  Hi Dan. We have ticket acceptance with South Western Railway between Reading and London Waterloo. - Jordan\n",
      "customer: @GWRHelp Great, thanks Jordan  thumbs up  light skin tone \n",
      "----------------------------------------\n",
      "customer: @AmazonHelp Again what you understand bad service\n",
      "response:  We would be happy to dig in and make things right for you. Any particular mentions regarding the experience?  \n",
      "customer: @AmazonHelp  smiling face with horns  smiling face with horns  smiling face with horns  smiling face with horns \n",
      "----------------------------------------\n",
      "customer: @AskeBay GO LOOK AT YOUR PRIVATE DM --  Can't wait to hear the same BS from @AskeBay and @AmazonHelp  gains a new seller a customer wow no wonder they are #1\n",
      "response:  We have just replied to your Dm. We would need to review your account and for security reasons, we need your details through DM.^A\n",
      "customer: @AskeBay Already sent #ebay and of course still waiting #twitterarmy DM me w more stories  hello gorgeous\n",
      "----------------------------------------\n",
      "customer: @AmericanAir I did but it doesn’t matter at this point I’ve already been extremely inconvenienced\n",
      "response:  We see you're on your way now and we'll have you in EWR just as quickly as we can.\n",
      "customer: @AmericanAir Great!\n",
      "----------------------------------------\n",
      "customer: @AmazonHelp Hmmm, just checked and nothing there!\n",
      "response:  When you visit this order here: \n",
      "customer: @AmazonHelp Nope, it just says Track package and return requested...\n",
      "----------------------------------------\n",
      "customer: @AzureSupport Guys seeing only 'Error retrieving data on all Application insights with no changes since yesterday. Everything ok?\n",
      "response:  Could you please DM us with your SubID and region so we can take a closer look? Thank you!  \n",
      "customer: @AzureSupport  thumbs up \n",
      "----------------------------------------\n",
      "customer: @AzureSupport Guys seeing only 'Error retrieving data on all Application insights with no changes since yesterday. Everything ok?\n",
      "response:  Could you please DM us with your SubID and region so we can take a closer look? Thank you!  \n",
      "customer: @AzureSupport  thumbs up \n",
      "----------------------------------------\n",
      "customer: I'm craving for McDonald's right now aka I don't know who I am\n",
      "response:  The stomach wants what the stomach wants. See you soon?\n",
      "customer: @McDonalds well okay can you please deliver a cheeseburger to my address then?\n",
      "----------------------------------------\n",
      "customer: @nationalrailenq can I use the same ticket for the train as there is only a few mins between my train arriving and the next one leaving!\n",
      "response:  Yes this should be fine.\n",
      "customer: @nationalrailenq Ok great thanks!\n",
      "----------------------------------------\n",
      "customer: I hate how long it takes for people to board the airplane.  If @AmericanAir would listen and ban roller bags we would be in the Air already\n",
      "response:  John, thanks for your feedback. Our gate team is there to ensure we depart on time. We'll have you wheels up soon.\n",
      "customer: @AmericanAir Have a great trip! \n",
      "----------------------------------------\n",
      "customer: @VirginTrains If I buy an off-peak return journey (EUS-WBQ), is the return ticket valid for 1 month or only the day I specified?\n",
      "response:  It's valid for 28 days Dan. \n",
      "customer: @VirginTrains Awesome - thank you!\n",
      "----------------------------------------\n",
      "customer: @VirginTrains I bought it in the virgin sale a couple of months ago but for the wrong time - the station said it would be an extra £70\n",
      "response:  Unfortunately that is the only way sorry. \n",
      "customer: @VirginTrains Great.\n",
      "----------------------------------------\n",
      "customer: @sainsburys I haven't even logged in or anything so it won't know where the deliveries are coming from lol post code is me14 2sq\n",
      "response:  Hi there, we are working on making WWE 2K18 available for online purchase by Friday. Keep an eye out! Daryl.\n",
      "customer: @sainsburys Ok sweet thanks\n",
      "----------------------------------------\n",
      "customer:  worst delivery services #do not shop in amazon # ordrd prdct nt yt dlvrd 20 days some\n",
      "response:  Sorry to know about the delay. Have you reported the issue here: \n",
      "customer: @AmazonHelp Have made 3 escalations on dlvry still no rply # no updte in mbl app ,,, no prpr care on dlvry #bng good to online is bad#go legal is best\n",
      "----------------------------------------\n",
      "customer: @Ask_Spectrum Do you have all of my info and the problems we’ve been having over the past couple days?\n",
      "response:  Yes I do. \n",
      "customer: @Ask_Spectrum Awesome thank you\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The really great tweets! There are actually no changes above 3 or below -3\n",
    "my_tweet_rows = get_rows_above_delta(3, True)\n",
    "print_tweets(my_tweet_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['help', 0.8547008547008547],\n",
       " ['sorry', 2.5641025641025643],\n",
       " ['team', 1.0683760683760684],\n",
       " ['hi', 2.7777777777777777],\n",
       " ['yes', 1.0683760683760684],\n",
       " ['service', 1.9230769230769231],\n",
       " ['please', 1.9230769230769231],\n",
       " ['dm', 1.9230769230769231],\n",
       " ['email', 0.8547008547008547],\n",
       " ['let', 0.8547008547008547],\n",
       " ['know', 0.8547008547008547],\n",
       " ['look', 1.0683760683760684],\n",
       " ['it', 0.8547008547008547],\n",
       " ['lapse', 1.2820512820512822],\n",
       " ['general', 1.2820512820512822],\n",
       " ['nature', 1.2820512820512822],\n",
       " ['concern', 1.2820512820512822],\n",
       " ['clarissa', 1.2820512820512822],\n",
       " ['thank', 0.8547008547008547]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words(my_tweet_rows, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
