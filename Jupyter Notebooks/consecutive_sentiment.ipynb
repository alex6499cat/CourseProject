{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import bisect\n",
    "from gensim import models,corpora,utils\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp_dir = 'C:\\\\Users\\\\Neal_McBeal\\\\Documents\\\\cs410project\\\\corenlp'\n",
    "\n",
    "# Set the CORENLP_HOME environment variable to point to the installation location\n",
    "import os\n",
    "os.environ[\"CORENLP_HOME\"] = corenlp_dir\n",
    "\n",
    "# Import client module\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threads = pd.read_csv('threads.csv', dtype = {'tweet_id': str})\n",
    "mask = (threads[\"length\"] > 2) &  threads[\"verify_alternance\"] & threads[\"inbound_first\"] & threads[\"verify_thread\"] & threads[\"verify_time\"]  \n",
    "threads_ok = threads[mask].copy()\n",
    "threads_ok.set_index('tweet_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>tweet_l</th>\n",
       "      <th>author_l</th>\n",
       "      <th>inbound_l</th>\n",
       "      <th>time_l</th>\n",
       "      <th>length</th>\n",
       "      <th>verify_thread</th>\n",
       "      <th>verify_time</th>\n",
       "      <th>verify_alternance</th>\n",
       "      <th>inbound_first</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115712</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>8|6|5|4|3|1|2</td>\n",
       "      <td>115712|sprintcare|115712|sprintcare|115712|spr...</td>\n",
       "      <td>True|False|True|False|True|False|True</td>\n",
       "      <td>2017-10-31 21:45:10+00:00|2017-10-31 21:46:24+...</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>18|17|16|15|12|11</td>\n",
       "      <td>115713|sprintcare|115713|sprintcare|115713|spr...</td>\n",
       "      <td>True|False|True|False|True|False</td>\n",
       "      <td>2017-10-31 19:56:01+00:00|2017-10-31 19:59:13+...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ask_Spectrum</td>\n",
       "      <td>Ask_Spectrum</td>\n",
       "      <td>29|28|24|21|22|25|26|27</td>\n",
       "      <td>115716|Ask_Spectrum|115716|Ask_Spectrum|115716...</td>\n",
       "      <td>True|False|True|False|True|False|True|False</td>\n",
       "      <td>2017-10-31 22:01:35+00:00|2017-10-31 22:05:37+...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>115716</td>\n",
       "      <td>Ask_Spectrum</td>\n",
       "      <td>29|28|24|21|23</td>\n",
       "      <td>115716|Ask_Spectrum|115716|Ask_Spectrum|115716</td>\n",
       "      <td>True|False|True|False|True</td>\n",
       "      <td>2017-10-31 22:01:35+00:00|2017-10-31 22:05:37+...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VerizonSupport</td>\n",
       "      <td>VerizonSupport</td>\n",
       "      <td>36|34|35|37</td>\n",
       "      <td>115719|VerizonSupport|115719|VerizonSupport</td>\n",
       "      <td>True|False|True|False</td>\n",
       "      <td>2017-10-31 22:10:46+00:00|2017-10-31 22:13:33+...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id    company_name                  tweet_l  \\\n",
       "tweet_id                                                            \n",
       "2                 115712      sprintcare            8|6|5|4|3|1|2   \n",
       "11            sprintcare      sprintcare        18|17|16|15|12|11   \n",
       "27          Ask_Spectrum    Ask_Spectrum  29|28|24|21|22|25|26|27   \n",
       "23                115716    Ask_Spectrum           29|28|24|21|23   \n",
       "37        VerizonSupport  VerizonSupport              36|34|35|37   \n",
       "\n",
       "                                                   author_l  \\\n",
       "tweet_id                                                      \n",
       "2         115712|sprintcare|115712|sprintcare|115712|spr...   \n",
       "11        115713|sprintcare|115713|sprintcare|115713|spr...   \n",
       "27        115716|Ask_Spectrum|115716|Ask_Spectrum|115716...   \n",
       "23           115716|Ask_Spectrum|115716|Ask_Spectrum|115716   \n",
       "37              115719|VerizonSupport|115719|VerizonSupport   \n",
       "\n",
       "                                            inbound_l  \\\n",
       "tweet_id                                                \n",
       "2               True|False|True|False|True|False|True   \n",
       "11                   True|False|True|False|True|False   \n",
       "27        True|False|True|False|True|False|True|False   \n",
       "23                         True|False|True|False|True   \n",
       "37                              True|False|True|False   \n",
       "\n",
       "                                                     time_l  length  \\\n",
       "tweet_id                                                              \n",
       "2         2017-10-31 21:45:10+00:00|2017-10-31 21:46:24+...       7   \n",
       "11        2017-10-31 19:56:01+00:00|2017-10-31 19:59:13+...       6   \n",
       "27        2017-10-31 22:01:35+00:00|2017-10-31 22:05:37+...       8   \n",
       "23        2017-10-31 22:01:35+00:00|2017-10-31 22:05:37+...       5   \n",
       "37        2017-10-31 22:10:46+00:00|2017-10-31 22:13:33+...       4   \n",
       "\n",
       "          verify_thread  verify_time  verify_alternance  inbound_first  \n",
       "tweet_id                                                                \n",
       "2                  True         True               True           True  \n",
       "11                 True         True               True           True  \n",
       "27                 True         True               True           True  \n",
       "23                 True         True               True           True  \n",
       "37                 True         True               True           True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads_ok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(\"emojiTranslatedCleanedNoUnderscore.csv\", na_filter= False, parse_dates = ['created_at'],\n",
    "                      dtype = {'tweet_id': str,'in_response_to_tweet_id': str, 'inbound':bool, 'response_tweet_id':str })\n",
    "full_df.set_index(\"tweet_id\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:47+00:00</td>\n",
       "      <td>I understand. I would like to assist you. We ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:11:45+00:00</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:08:27+00:00</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 21:54:49+00:00</td>\n",
       "      <td>Please send us a Private Message so that we c...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:49:35+00:00</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 21:46:24+00:00</td>\n",
       "      <td>Can you please send us a private message, so ...</td>\n",
       "      <td>5,7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 21:45:10+00:00</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:35+00:00</td>\n",
       "      <td>This is saddening to hear. Please shoot us a ...</td>\n",
       "      <td></td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:04:47+00:00</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>11,13,14</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 20:03:31+00:00</td>\n",
       "      <td>We understand your concerns and we'd like for...</td>\n",
       "      <td>12</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 20:00:43+00:00</td>\n",
       "      <td>@sprintcare Since I signed up with you....Sinc...</td>\n",
       "      <td>15</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 19:59:13+00:00</td>\n",
       "      <td>H there! We'd definitely like to work with yo...</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 19:56:01+00:00</td>\n",
       "      <td>y’all lie about your “great” connection. 5 ba...</td>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-31 22:10:10+00:00</td>\n",
       "      <td>Please send me a private message so that I ca...</td>\n",
       "      <td></td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14</td>\n",
       "      <td>115715</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-31 22:03:34+00:00</td>\n",
       "      <td>whenever I contact customer support, they tel...</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0   author_id  inbound                created_at  \\\n",
       "tweet_id                                                              \n",
       "1                  0  sprintcare    False 2017-10-31 22:10:47+00:00   \n",
       "2                  1      115712     True 2017-10-31 22:11:45+00:00   \n",
       "3                  2      115712     True 2017-10-31 22:08:27+00:00   \n",
       "4                  3  sprintcare    False 2017-10-31 21:54:49+00:00   \n",
       "5                  4      115712     True 2017-10-31 21:49:35+00:00   \n",
       "6                  5  sprintcare    False 2017-10-31 21:46:24+00:00   \n",
       "8                  6      115712     True 2017-10-31 21:45:10+00:00   \n",
       "11                 7  sprintcare    False 2017-10-31 22:10:35+00:00   \n",
       "12                 8      115713     True 2017-10-31 22:04:47+00:00   \n",
       "15                 9  sprintcare    False 2017-10-31 20:03:31+00:00   \n",
       "16                10      115713     True 2017-10-31 20:00:43+00:00   \n",
       "17                11  sprintcare    False 2017-10-31 19:59:13+00:00   \n",
       "18                12      115713     True 2017-10-31 19:56:01+00:00   \n",
       "19                13  sprintcare    False 2017-10-31 22:10:10+00:00   \n",
       "20                14      115715     True 2017-10-31 22:03:34+00:00   \n",
       "\n",
       "                                                       text response_tweet_id  \\\n",
       "tweet_id                                                                        \n",
       "1          I understand. I would like to assist you. We ...                 2   \n",
       "2             @sprintcare and how do you propose we do that                     \n",
       "3         @sprintcare I have sent several private messag...                 1   \n",
       "4          Please send us a Private Message so that we c...                 3   \n",
       "5                                        @sprintcare I did.                 4   \n",
       "6          Can you please send us a private message, so ...               5,7   \n",
       "8                 @sprintcare is the worst customer service            9,6,10   \n",
       "11         This is saddening to hear. Please shoot us a ...                     \n",
       "12        @sprintcare You gonna magically change your co...          11,13,14   \n",
       "15         We understand your concerns and we'd like for...                12   \n",
       "16        @sprintcare Since I signed up with you....Sinc...                15   \n",
       "17         H there! We'd definitely like to work with yo...                16   \n",
       "18         y’all lie about your “great” connection. 5 ba...                17   \n",
       "19         Please send me a private message so that I ca...                     \n",
       "20         whenever I contact customer support, they tel...                19   \n",
       "\n",
       "         in_response_to_tweet_id  \n",
       "tweet_id                          \n",
       "1                            3.0  \n",
       "2                            1.0  \n",
       "3                            4.0  \n",
       "4                            5.0  \n",
       "5                            6.0  \n",
       "6                            8.0  \n",
       "8                                 \n",
       "11                          12.0  \n",
       "12                          15.0  \n",
       "15                          16.0  \n",
       "16                          17.0  \n",
       "17                          18.0  \n",
       "18                                \n",
       "19                          20.0  \n",
       "20                                "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "**Warning! This will take around 9 hours to run. Output has been written to con_sent.csv. Recommended to skip this section and go to \"Observing Deltas\" instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pairs_df = pd.DataFrame(columns=['first_tweet_id','second_tweet_id','third_tweet_id','company','sentiment_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 01:52:56 INFO: Writing properties to tmp file: corenlp_server-d355efdad98d4661.props\n",
      "2020-11-30 01:52:56 INFO: Starting server with command: java -Xmx6G -cp C:\\Users\\Neal_McBeal\\Documents\\cs410project\\corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9002 -timeout 200000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-d355efdad98d4661.props -annotators sentiment -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 122609 number of valid threads...\n",
      "Working on thread number:  120000 time:  01:57:34.741243\n",
      "Working on thread number:  121000 time:  02:00:16.186114\n",
      "Working on thread number:  122000 time:  02:03:00.530691\n"
     ]
    }
   ],
   "source": [
    "senti_value_order = [\"Very negative\", \"Negative\", \"Neutral\", \"Positive\", \"Very positive\"]\n",
    "def sentiment_score(sent_string):\n",
    "    if len(sent_string) > 0:\n",
    "        return senti_value_order.index(sent_string)\n",
    "    return 2\n",
    "\n",
    "def sentiment_average(sent_list):\n",
    "    if len(sent_list) == 0:\n",
    "        return 0\n",
    "    total = 0\n",
    "    for sent in sent_list:\n",
    "        total += sentiment_score(sent)\n",
    "    return total / len(sent_list)\n",
    "\n",
    "# sentiment_pairs = []\n",
    "company_col, tweetl_col, authorl_col, inboundl_col = \\\n",
    "    threads_ok.columns.get_indexer(['company_name','tweet_l','author_l','inbound_l'])\n",
    "with CoreNLPClient(annotators=['sentiment'], \n",
    "                   memory='6G', endpoint='http://localhost:9002', be_quiet=True, timeout = 200000) as client:\n",
    "    print(\"Processing\", len(threads_ok) ,\"number of valid threads...\")\n",
    "    for row in range(119232, len(threads_ok)):\n",
    "        if row % 1000 == 0:\n",
    "            print(\"Working on thread number: \", row, \"time: \", dt.datetime.now().time())\n",
    "        company, raw_tweetl, raw_authorl, raw_inboundl = \\\n",
    "            threads_ok.iloc[row,[company_col, tweetl_col, authorl_col, inboundl_col]]\n",
    "        tweet_list = raw_tweetl.split('|')\n",
    "        author_list = raw_authorl.split('|')\n",
    "        inbound_list = raw_inboundl.split('|')\n",
    "        \n",
    "        # process first tweet standalone\n",
    "        tweet_idx3 = None\n",
    "        tweet_idx1 = tweet_list[0]\n",
    "        tweet1_text = full_df.loc[tweet_idx1, 'text']\n",
    "        doc1 = client.annotate(tweet1_text)\n",
    "        sent_list = []\n",
    "        if len(tweet1_text) > 0:\n",
    "            for sentence in doc1.sentence:\n",
    "                sent_list.append(sentence.sentiment)\n",
    "\n",
    "        doc1_sentiment = 2 if len(sent_list) == 0 else sentiment_average(sent_list)\n",
    "        \n",
    "        # process all consecutive pairs of customer tweets in the thread\n",
    "        for i in range(1,len(tweet_list)-1,2):\n",
    "            if not tweet_idx3 == None:\n",
    "                tweet_idx1 = tweet_idx3\n",
    "                tweet1_text = tweet3_text\n",
    "                doc1_sentiment = doc3_sentiment\n",
    "            \n",
    "            tweet_idx2, tweet_idx3 = tweet_list[i:i+2]\n",
    "            tweet2_text = full_df.loc[tweet_idx2, 'text']\n",
    "            tweet3_text = full_df.loc[tweet_idx3, 'text']\n",
    "            \n",
    "            doc3 = client.annotate(tweet3_text)\n",
    "            \n",
    "            sent_list = []\n",
    "            if len(tweet3_text) > 0:\n",
    "                for sentence in doc3.sentence:\n",
    "                    sent_list.append(sentence.sentiment)\n",
    "                \n",
    "            doc3_sentiment = 2 if len(sent_list) == 0 else sentiment_average(sent_list)\n",
    "            \n",
    "            delta = doc3_sentiment - doc1_sentiment\n",
    "            sentiment_pairs.append([tweet_idx1, tweet_idx2, tweet_idx3, company, delta])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pairs_df = pd.DataFrame(data=sentiment_pairs, columns=['first_tweet_id','second_tweet_id','third_tweet_id','company','sentiment_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pairs_df.to_csv(\"con_sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8', '6', '5', 'sprintcare', 1.0]\n",
      "['5', '4', '3', 'sprintcare', -1.0]\n",
      "['3', '1', '2', 'sprintcare', 1.0]\n",
      "['18', '17', '16', 'sprintcare', 1.3333333333333333]\n",
      "['16', '15', '12', 'sprintcare', -0.5]\n",
      "['29', '28', '24', 'Ask_Spectrum', 1.0]\n",
      "['24', '21', '22', 'Ask_Spectrum', -1.0]\n",
      "['22', '25', '26', 'Ask_Spectrum', 1.0]\n",
      "['29', '28', '24', 'Ask_Spectrum', 1.0]\n",
      "['24', '21', '23', 'Ask_Spectrum', -1.0]\n",
      "['36', '34', '35', 'VerizonSupport', 3.0]\n",
      "somebody from @VerizonSupport please help meeeeee  weary face  weary face  weary face  weary face  I'm having the worst luck with your customer service\n",
      " Help has arrived! We are sorry to see that you are having trouble. How can we help?\n",
      "@VerizonSupport I finally got someone that helped me, thanks!\n",
      "['59', '58', '57', 'VerizonSupport', 0.0]\n",
      "['57', '56', '55', 'VerizonSupport', 1.0]\n",
      "['55', '54', '53', 'VerizonSupport', 0.0]\n",
      "['53', '52', '51', 'VerizonSupport', -0.5]\n",
      "['66', '64', '65', 'ChipotleTweets', 1.0]\n",
      "['76', '75', '74', 'ChipotleTweets', 0.5]\n",
      "['163', '162', '161', 'ChipotleTweets', -1.0]\n",
      "['180', '178', '179', 'AskPlayStation', 0.0]\n",
      "['185', '184', '183', 'AskPlayStation', 0.0]\n"
     ]
    }
   ],
   "source": [
    "for sp in sentiment_pairs:\n",
    "    print(sp)\n",
    "    if sp[4] >= 2.5:\n",
    "        print(full_df.loc[sp[0], 'text'])\n",
    "        print(full_df.loc[sp[1], 'text'])\n",
    "        print(full_df.loc[sp[2], 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing Deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_tweet_id</th>\n",
       "      <th>second_tweet_id</th>\n",
       "      <th>third_tweet_id</th>\n",
       "      <th>company</th>\n",
       "      <th>sentiment_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            first_tweet_id  second_tweet_id  third_tweet_id     company  \\\n",
       "Unnamed: 0                                                                \n",
       "0                        8                6               5  sprintcare   \n",
       "1                        5                4               3  sprintcare   \n",
       "2                        3                1               2  sprintcare   \n",
       "3                       18               17              16  sprintcare   \n",
       "4                       16               15              12  sprintcare   \n",
       "\n",
       "            sentiment_change  \n",
       "Unnamed: 0                    \n",
       "0                   1.000000  \n",
       "1                  -1.000000  \n",
       "2                   1.000000  \n",
       "3                   1.333333  \n",
       "4                  -0.500000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pairs_df = pd.read_csv(\"con_sent.csv\")\n",
    "sentiment_pairs_df.set_index('Unnamed: 0', inplace = True)\n",
    "sentiment_pairs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = sentiment_pairs_df.shape[0]\n",
    "def lower_sent_for_top_p_responses(percent=.001):\n",
    "    num_top = round(num_rows * percent)\n",
    "    deltas = []\n",
    "    \n",
    "    for row in range(num_rows):  \n",
    "        change = sentiment_pairs_df.iloc[row][4]\n",
    "        bisect.insort(deltas, change)\n",
    "        \n",
    "        if len(deltas) > num_top:\n",
    "            deltas.pop(0)\n",
    "            \n",
    "    return deltas        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.1666666666666665,\n",
       " 2.166666666666667,\n",
       " 2.2,\n",
       " 2.2,\n",
       " 2.2,\n",
       " 2.2,\n",
       " 2.25,\n",
       " 2.25,\n",
       " 2.25,\n",
       " 2.333333333333333,\n",
       " 2.333333333333333,\n",
       " 2.333333333333333,\n",
       " 2.333333333333333,\n",
       " 2.333333333333333,\n",
       " 2.333333333333333,\n",
       " 2.333333333333333,\n",
       " 2.333333333333333,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.5,\n",
       " 2.666666666666667,\n",
       " 2.666666666666667,\n",
       " 2.666666666666667,\n",
       " 2.666666666666667,\n",
       " 2.666666666666667,\n",
       " 2.666666666666667,\n",
       " 2.666666666666667,\n",
       " 2.75,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top001 = lower_sent_for_top_p_responses()\n",
    "top001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = sentiment_pairs_df.shape[0]\n",
    "def get_rows_above_delta2():\n",
    "    row_ids = []\n",
    "    \n",
    "    for row in range(num_rows):\n",
    "        row_data = sentiment_pairs_df.iloc[row]\n",
    "        change = row_data[4]\n",
    "        if change >= 2:\n",
    "            row_ids.append(row_data)\n",
    "        \n",
    "    return row_ids\n",
    "\n",
    "def get_rows_at_delta3():\n",
    "    row_ids = []\n",
    "    \n",
    "    for row in range(num_rows):\n",
    "        row_data = sentiment_pairs_df.iloc[row]\n",
    "        change = row_data[4]\n",
    "        if change == 3:\n",
    "            row_ids.append(row_data)\n",
    "        \n",
    "    return row_ids\n",
    "\n",
    "def get_rows_below_deltaneg2():\n",
    "    row_ids = []\n",
    "    \n",
    "    for row in range(num_rows):\n",
    "        row_data = sentiment_pairs_df.iloc[row]\n",
    "        change = row_data[4]\n",
    "        if change <= -2:\n",
    "            row_ids.append(row_data)\n",
    "        \n",
    "    return row_ids\n",
    "\n",
    "def get_rows_at_deltaneg3():\n",
    "    row_ids = []\n",
    "    \n",
    "    for row in range(num_rows):\n",
    "        row_data = sentiment_pairs_df.iloc[row]\n",
    "        change = row_data[4]\n",
    "        if change == -3:\n",
    "            row_ids.append(row_data)\n",
    "        \n",
    "    return row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_rows = get_rows_above_delta2()\n",
    "best_rows = get_rows_at_delta3()\n",
    "bad_rows = get_rows_below_deltaneg2()\n",
    "worst_rows = get_rows_at_deltaneg3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = '----------------------------------------'\n",
    "def print_best_examples(num_to_print=5):\n",
    "    print(separator)\n",
    "    for i in range(num_to_print):\n",
    "        row = best_rows[i]\n",
    "        first_text = full_df.loc[str(row[0])]['text']\n",
    "        second_text = full_df.loc[str(row[1])]['text']\n",
    "        third_text = full_df.loc[str(row[2])]['text']\n",
    "        \n",
    "        print(\"customer:\", first_text)\n",
    "        print(\"response:\", second_text)\n",
    "        print(\"customer:\", third_text)\n",
    "        print(separator)\n",
    "        \n",
    "def print_worst_examples(num_to_print=5):\n",
    "    print(separator)\n",
    "    for i in range(num_to_print):\n",
    "        row = worst_rows[i]\n",
    "        first_text = full_df.loc[str(row[0])]['text']\n",
    "        second_text = full_df.loc[str(row[1])]['text']\n",
    "        third_text = full_df.loc[str(row[2])]['text']\n",
    "        \n",
    "        print(\"customer:\", first_text)\n",
    "        print(\"response:\", second_text)\n",
    "        print(\"customer:\", third_text)\n",
    "        print(separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "customer: somebody from @VerizonSupport please help meeeeee  weary face  weary face  weary face  weary face  I'm having the worst luck with your customer service\n",
      "response:  Help has arrived! We are sorry to see that you are having trouble. How can we help?\n",
      "customer: @VerizonSupport I finally got someone that helped me, thanks!\n",
      "----------------------------------------\n",
      "customer: @AppleSupport Thanks, thing is I still have like 81 cents in credit and won't let me do that until I have zero credit\n",
      "response:  Try contacting our iTunes Store team here for more help: \n",
      "customer: @AppleSupport Awesome, thanks\n",
      "----------------------------------------\n",
      "customer: @Uber_Support Thanks - our baby is &lt;12mos and we need our car seat to fly so I was wondering if we can bring our own car seat and install via belt buckle in any UberX to go to the airport\n",
      "response:  Hi there! Yes, you're always welcome to bring your own car seat along for the ride.\n",
      "customer: @Uber_Support Ok great, thanks!\n",
      "----------------------------------------\n",
      "customer: @ATVIAssist Black ops 3 on Xbox one for me runs bad every game and every map I have stutter lag problems and it’s annoying \n",
      "response:  Good evening, I'm not seeing much connection issues occurring. Are you playing on a wired or wireless connection? \n",
      "customer: @ATVIAssist Wired and I’ve got fiber Internet so it’s nothing to do with connection plus I’m playing solo on zombies so should run totally fine\n",
      "----------------------------------------\n",
      "customer: Another awful experience with ; never forget  ;retweet and fly ANY other carrier;\n",
      "response:  This definitely isn't what we want to hear, Lynn. Can you tell us what happened? \n",
      "customer: @British_Airways  Stop wining and fly with Albatros Airlines, good luck.\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "customer: Guys please deep this! I was ranting about the shit service I received from  and this fake amazon account  posed as them and asked for my card details, address etc then BLOCKED ME  face with tears of joy  face with tears of joy  face with tears of joy  face with tears of joy  weary face  weary face  weary face  weary face Beware guys ! \n",
      "response:  Thanks for bringing this to our attention! I have reported this to the appropriate team. \n",
      "customer: @AmazonHelp  Looool idiots  face with tears of joy  face with tears of joy \n",
      "----------------------------------------\n",
      "customer: @GWRHelp another outstanding day for the 16:25 Paddington to Oxford I see  thumbs down  light skin tone \n",
      "response:  Hi Steve, sorry for the delay currently 10 minutes late I don't have the cause for this just yet. -Andy\n",
      "customer: @GWRHelp Hi Andy, whatever holds it up at southall most days seems to have been worse than usual...\n",
      "----------------------------------------\n",
      "customer: Someone bring me some McDonald's breakfast I'll love you forever\n",
      "response:  Attention Earth! We need a hero to step up and get Tyler some breakfast, pronto! :)\n",
      "customer: @McDonalds  Supporting the NFL is supporting racism \n",
      "----------------------------------------\n",
      "customer: Bloody hell its hot in this @VirginTrains - my eyeballs are genuinely sticking in their sockets  expressionless face  fire \n",
      "response:  Apologies Valerie! Please speak to the onboard team as they should be able to adjust the temperature for you \n",
      "customer: @VirginTrains I never saw one  tired face \n",
      "----------------------------------------\n",
      "customer: @USCellularCares iPhone 8+ 64GB gold\n",
      "response:  That device is on backorder. We’re waiting on Apple to send more. Once the phone is available it will ship in the order it was received. \n",
      "customer: @USCellularCares you all have different things to say, the stores and costumer service said they’re not on back order anymore and now they are  person shrugging  light skin tone ‍ female sign ️\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_best_examples()\n",
    "print_worst_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('stopwords.txt',\"r\")\n",
    "stoplist = stopwords.read().splitlines() \n",
    "\n",
    "def get_texts(rows):\n",
    "    texts = []\n",
    "    for row in rows:\n",
    "        cs_tweet_id = row[1]\n",
    "        cs_tweet_text = full_df.loc[str(cs_tweet_id)]['text']\n",
    "        cs_tweet_text = [word for word in cs_tweet_text.lower().split() if word not in stoplist]\n",
    "        texts.append(cs_tweet_text)\n",
    "        \n",
    "    return texts\n",
    "    \n",
    "goodTweetList = list(sent_to_words(get_texts(best_rows)))\n",
    "badTweetList = list(sent_to_words(get_texts(worst_rows)))\n",
    "gTweetList = list(sent_to_words(get_texts(good_rows)))\n",
    "bTweetList = list(sent_to_words(get_texts(bad_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodFrequency = defaultdict(int)\n",
    "goodTotal = 0\n",
    "for text in goodTweetList:\n",
    "    for token in text:\n",
    "        goodFrequency[token] += 1\n",
    "        goodTotal += 1\n",
    "\n",
    "badFrequency = defaultdict(int)\n",
    "badTotal = 0\n",
    "for text in badTweetList:\n",
    "    for token in text:\n",
    "        badFrequency[token] += 1\n",
    "        badTotal += 1\n",
    "        \n",
    "gFrequency = defaultdict(int)\n",
    "gTotal = 0\n",
    "for text in gTweetList:\n",
    "    for token in text:\n",
    "        gFrequency[token] += 1\n",
    "        gTotal += 1\n",
    "        \n",
    "bFrequency = defaultdict(int)\n",
    "bTotal = 0\n",
    "for text in bTweetList:\n",
    "    for token in text:\n",
    "        bFrequency[token] += 1\n",
    "        bTotal += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(frequency, total, top):\n",
    "    measures = []\n",
    "    \n",
    "    for word in frequency:\n",
    "        count = frequency[word]\n",
    "        if len(measures) < top or count > measures[0]:\n",
    "            bisect.insort(measures, count)\n",
    "            if len(measures) > top:\n",
    "                measures.pop(0)\n",
    "    ret = []\n",
    "    for word in frequency:\n",
    "        count = frequency[word]\n",
    "        if count >= measures[0]:\n",
    "            ret.append([word, count*100.0/total])\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sorry', 2.5641025641025643],\n",
       " ['hi', 2.7777777777777777],\n",
       " ['service', 1.9230769230769231],\n",
       " ['please', 1.9230769230769231],\n",
       " ['dm', 1.9230769230769231],\n",
       " ['lapse', 1.2820512820512822],\n",
       " ['general', 1.2820512820512822],\n",
       " ['nature', 1.2820512820512822],\n",
       " ['concern', 1.2820512820512822],\n",
       " ['clarissa', 1.2820512820512822]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words(goodFrequency, goodTotal, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['help', 1.3339657319025315],\n",
       " ['sorry', 1.5859370368174541],\n",
       " ['look', 0.7025552854686666],\n",
       " ['you', 1.093851900160076],\n",
       " ['dm', 1.1323886879705936],\n",
       " ['please', 2.410031422303907],\n",
       " ['like', 0.744056441572301],\n",
       " ['hi', 1.5385071441275864],\n",
       " ['here', 1.0108495879528072],\n",
       " ['let', 0.8804173830556709],\n",
       " ['know', 0.7974150708484022]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words(gFrequency, gTotal, top=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['please', 3.061224489795918],\n",
       " ['we', 1.530612244897959],\n",
       " ['that', 2.0408163265306123],\n",
       " ['purchase', 1.530612244897959],\n",
       " ['steam', 3.061224489795918],\n",
       " ['key', 1.530612244897959],\n",
       " ['let', 2.0408163265306123],\n",
       " ['know', 2.0408163265306123],\n",
       " ['concern', 1.530612244897959],\n",
       " ['could', 1.530612244897959],\n",
       " ['ok', 1.530612244897959],\n",
       " ['sent', 1.530612244897959],\n",
       " ['signals', 1.530612244897959],\n",
       " ['box', 1.530612244897959],\n",
       " ['helps', 1.530612244897959],\n",
       " ['allan', 1.530612244897959],\n",
       " ['best', 1.530612244897959]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words(badFrequency, badTotal, top=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['let', 0.840945338552994],\n",
       " ['know', 0.7636170315596152],\n",
       " ['help', 1.367744429945387],\n",
       " ['you', 1.2517519694553187],\n",
       " ['please', 2.237687883620898],\n",
       " ['dm', 0.9521047798559761],\n",
       " ['there', 0.8216132618046493],\n",
       " ['here', 0.9376057222947175],\n",
       " ['hi', 1.681890677105988],\n",
       " ['sorry', 1.6915567154801605],\n",
       " ['thank', 0.6862887245662366]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words(bFrequency, bTotal, top=11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
